#+TITLE:
#+LATEX_HEADER: \usepackage{fancyhdr}
# #+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amsthm}
# #+LATEX_HEADER: \usepackage{indentfirst}
#+OPTIONS: toc:nil
#+BIND: org-export-latex-title-command ""
#+LATEX: \setcounter{secnumdepth}{-1}
#+LATEX: \setlength{\parindent}{0in}
#+LATEX: \addtolength{\parskip}{\baselineskip}
#+LATEX: \hypersetup{hidelinks=true}

#+LATEX: \newcommand{\reals}{\mathbb{R}}
#+LATEX: \newcommand{\ints}{\mathbb{Z}}
#+LATEX: \newcommand{\rplus}{\mathbb{R^+}}
#+LATEX: \newcommand{\zplus}{\mathbb{Z^+}}
#+LATEX: \newcommand{\naturals}{\mathbb{N}}
#+LATEX: \newcommand{\rats}{\mathbb{Q}}
#+LATEX: \newcommand{\cees}{\mathbb{C}}
#+LATEX: \newcommand{\ncol}[1]{\left(\begin{smallmatrix}#1\end{smallmatrix}\right) }

#+LATEX: \widowpenalty=300
#+LATEX: \clubpenalty=300
#+LATEX: \setlength{\parskip}{3ex plus 2ex minus 2ex}

#+LATEX: \newtheorem*{example}{Example}
#+LATEX: \theoremstyle{definition}
#+LATEX: \newtheorem{defn}{Definition}
#+LATEX: \newtheorem{theorem}{Theorem}

# Setting up SLIME:
# Open up the org file.
# M-x slime-mode
# Go to sbcl and eval (swank:create-server)
# M-x slime
# Use C-x C-e to eval, as Org takes most of the keybindings

* Neural Networks and Their Theoretical Capabilities
#+LATEX: \pagestyle{fancy}
#+LATEX: \fancyhead{}
#+LATEX: \rhead{\textit{Aaron Decker, \today}}
#+LATEX: \lhead{\textit{Math Seminar}}
#+LATEX: \small

# ** Project Schedule
# *** Introduction Paper due 9/25/2014
# *** Demonstration of the Equivalence of Various Perceptrons Networks due 2014-09-23
# *** Statement and Proof of Perceptron Training algorithm due 2014-09-30
# *** Turing Equivalence 2014-09-30
# *** Universality Theorem 2014-10-07
# *** Statement and Proof of Backpropogation algo? 2014-10-14

# a nice paper on lambda calculus is at http://www.cse.chalmers.se/research/group/logic/TypesSS05/Extra/geuvers.pdf

** Overview of Neural Networks
A neural network is a system in which many similar functions, called /neurons/, are composed together in order to classify inputs, perform some computation,
or approximate some function.
Neural networks are used today in various machine-learning applications such as handwriting- or speech-recognition, and have several interesting mathematical properties.

This paper will introduce two mathematical models of neurons, the basic workings of neural networks,
and then will proceed to examine their theoretical capabilities.
First, the ability of certain neurons to compute various boolean functions will be demonstrated.
This leads to the intuition that recurrent neural networks are Turing-complete, which will then be proved.
# The proof will then be extended by outlining changes to the network that could be made to make a Turing-complete version using the
# more popular perceptron neuron.

*** Definition of a Neuron
# See Figure 1.4, page 8, of "Neural Networks A Comprehensive Foundation" by Simon Haykin.
The idea for neural networks is borrowed from the field of biology; the human brain uses cells called neurons for cognition.
Neurons are joined with one another via connections called synapses.
Neurons create voltages based upon the voltages on certain synapses that act as inputs.
Thus when the collective voltage on the input synapses exceeds a certain level the neuron becomes excited and produces a higher voltage on the output synapses.

A neuron is modeled mathematically as a function $f(x_1, x_2, \ldots, x_n) = \phi( \Sigma_{i=1}^n w_ix_i )$, where $\{w_1, w_2, \ldots\, w_n\}$ is a set of weights,
with each weight $w_i$ corresponding to an input $x_i$, and where $\phi$ is the activation function that determines the output of the neuron based
on the sum of the products of the weights and inputs. For the sake of brevity we will also notate the weight and input vectors as $\vec{w}$ and $\vec{x}$, respectively.
$\Sigma_{i=1}^n w_ix_i$ calculates the collective weighted input; this total is then passed to the activation function $\phi$ which uses the collective weighted input to generate an output.
Note that the neuron is stateless; that is, output is determined wholly by the input.

A neuron could be also thought of more generally as a partial application of $\phi$ and $\vec{w}$ over the function $F( \phi, \vec{w}, \vec{x} )$.
Such a definition may be useful for implementation of a neural network in software.

There are two popular activation functions, the perceptron and the sigmoid.

Having been invented in 1957 by Frank Rosenblatt, the perceptron was among the first activation functions to be implemented.
It can be used as a standalone classifier on linearly separable data.
The perceptron can be defined as the function
\begin{equation}
\label{eqn:perceptron}\phi_P(x) = \left\{ \begin{array}{lr} 0 & : x + b \leq 0 \\ 1 & : x + b > 0 \end{array} \right.
\end{equation}
where $b$ is a bias that is specific to the neuron.
Notice that the bias $b$ of the perceptron is sometimes denoted by a number written inside the neuron if displayed in an image.
# TODO add diagrams of the neurons

The sigmoid function can be defined as
\begin{equation}
\label{eqn:sigmoid} \phi_S(x) = \sigma(x) = \frac{1}{1 + e^{-x}}
\end{equation}
Though bearing some resemblance to the perceptron, the sigmoid function has the advantage of being smooth and thus differentiable.
These properties make training a neural network composed of sigmoid neurons much easier than a similar network composed of perceptron neurons.

\begin{figure}
\includegraphics[width=4.5in]{example_neurons.png}
\caption{Example perceptron and sigmoid neurons}
\label{fig:example_neurons}
\end{figure}

\begin{example}
Consider the neurons in Figure~\ref{fig:example_neurons}.
Let $x_1 = 3, x_2 = 2, x_3 = -0.5$.
Both of the neurons will have the same aggregate input passed to their activation functions.
To determine the aggregate input, multiply the inputs by their respective weights and then sum the products:
$w_1*x_1 + w_2*x_2 + w_3*x_3 = 3*3 + -1*2 + 1*-0.5 = 6.5$
The perceptron will output $1$ since $\phi(6.5) = 1$ (see Equation \ref{eqn:perceptron}).
The sigmoid will then output $\sigma(6.5) = \frac{1}{1 + e^{-6.5}} \approx 0.9985$.
\end{example}

** Construction of Neural Networks

More complex behavior can be created by linking the outputs of some neurons into the inputs of other neurons.
This is how the human brain is constructed.
#+LATEX: An example of a neural network is shown in Figure~\ref{fig:hidden-layer-diagram}.
The network pictured is considered a four-layer sigmoid network because each layer besides the input layer consists of sigmoid neurons as denoted by
the sigmoid shape inscribed in the representation of each neuron.
The input layer does not contain actual neurons but rather is drawn by convention to show the inputs being fed to the second layer.
The hidden layers encompass all of the neurons between the input layer and the output layer.

The output layer contains the neurons whose output is interpreted as the output of the network.
In the figure shown the output layer only contains one output neuron.
It is possible to have more than one output from a neural network;
for example, a binary number could be encoded in the outputs.

If no neuron takes as input an output that the neuron affected (i.e. there are no cycles in the graph), then the network is called a /feed-forward/ network.
If loops do exist, then the network is referred to as /recurrent/.

\begin{figure}
\includegraphics{neural_network_diagram.png}
\caption{A four-layer neural network of sigmoid neurons.}
\label{fig:hidden-layer-diagram}
\end{figure}

** Demonstration of the Equivalence of Various Perceptron Networks to Certain Boolean Logic Functions

# One attribute of neural networks, specifically perceptron networks, is the ability to compute boolean logic functions.
Neural networks can be used to compute boolean logic functions.
In this section the construction of various logic gates (devices that compute logical functions) from perceptron networks will be demonstrated.
Since traditional computers are constructed from logic gates, predominantly NAND\footnote{NAND is the composition of NOT and AND.} gates, it stands to reason that a neural network could be constructed
to simulate a traditional computer;\footnote{It should be noted, however, that most implementations of neural networks do just the opposite: neurons are simulated in software. This is due to the ease of construction of digital circuitry i.e. transistors over something that requires analog signals like a sigmoid neuron.}
intuitively this leads to the hypothesis that recurrent neural networks are Turing-complete.
This will be proved in the section following the current one.

Consider the following network consisting of one perceptron-type neuron, with inputs $\left(\begin{smallmatrix}x_1 \\ x_2 \end{smallmatrix}\right)$. \\
Let $\vec{w} = \left(\begin{smallmatrix} 1 \\ 1 \end{smallmatrix}\right)$ and $b=-1$.
Compare the behavior of the network to that of the AND function: \\
| $x_1$ | $x_2$ | $\vec{x}\cdot\vec{w}$ | $\vec{x}\cdot\vec{w} + b$ | Output | $x_1$ AND $x_2$ |
|     / |     > |                       |                           | >      |                 |
|-------+-------+-----------------------+---------------------------+--------+-----------------|
|     0 |     0 |                     0 |                        -1 |      0 |               0 |
|     0 |     1 |                     1 |                         0 |      0 |               0 |
|     1 |     0 |                     1 |                         0 |      0 |               0 |
|     1 |     1 |                     2 |                         1 |      1 |               1 |
Note how the network is equivalent to the AND function over the inputs for which AND is defined.

Now let $\vec{w} = \left(\begin{smallmatrix}1 \\ 1\end{smallmatrix}\right)$ and $b=0$.
Compare the behavior of the network to that of the OR function: \\
| $x_1$ | $x_2$ | $\vec{x}\cdot\vec{w}$ | $\vec{x}\cdot\vec{w} + b$ | Output | $x_1$ OR  $x_2$ |
|     / |     > |                       |                           |  >     |                 |
|-------+-------+-----------------------+---------------------------+--------+-----------------|
|     0 |     0 |                     0 |                         0 |      0 |               0 |
|     0 |     1 |                     1 |                         1 |      1 |               1 |
|     1 |     0 |                     1 |                         1 |      1 |               1 |
|     1 |     1 |                     2 |                         2 |      1 |               1 |
Now, simply by changing the bias, the network output becomes equivalent to the OR function over the domain of OR.

Let's also consider NAND.
Now let $\vec{w} = \left(\begin{smallmatrix} -1 \\ -1 \end{smallmatrix}\right)$ and $b=2$.
Compare the behavior of the network to that of the NAND function: \\
| $x_1$ | $x_2$ | $\vec{x}\cdot\vec{w}$ | $\vec{x}\cdot\vec{w} + b$ | Output | $x_1$ NAND  $x_2$ |
|     / |     > |                      |                          |      > |                   |
|-------+-------+----------------------+--------------------------+--------+-------------------|
|     0 |     0 |                    0 |                        2 |      1 |                 1 |
|     0 |     1 |                   -1 |                        1 |      1 |                 1 |
|     1 |     0 |                   -1 |                        1 |      1 |                 1 |
|     1 |     1 |                   -2 |                        0 |      0 |                 0 |
Thus a single two-input perceptron can compute NAND.

Computer scientists met with some difficulty when attempting to weight a single perceptron to compute the exclusive-or (XOR) function.
In fact, it is impossible to weight a single perceptron to do so.

# |    | $x_1$ | $x_2$ | output |
# |----+-------+-------+--------|
# | 1) | 0     | 0     | 0      |
# | 2) | 0     | 1     | 1      |
# | 3) | 1     | 0     | 1      |
# | 4) | 1     | 1     | 0      |

\begin{proof}
Let $P$ be a perceptron with two inputs $x_1$ and $x_2$, with associated weights $w_1$ and $w_2$, respectively, and a bias $b$.
Assume for the sake of contradiction that $P$ properly computes the XOR function.
This implies the following behavior:
\begin{center}
\begin{tabular}{r|rr|l}
 & $x_1$ & $x_2$ & Output $\left\{ \begin{array}{lr} 0 & : w_1x_1 + w_2x_2 + b \leq 0 \\ 1 & : w_1x_1 + w_2x_2 + b > 0 \end{array} \right.$ \\
\hline
1) & 0 & 0 & 0\\
2) & 0 & 1 & 1\\
3) & 1 & 0 & 1\\
4) & 1 & 1 & 0\\
\end{tabular}
\end{center}
Then the following must be true: \\
Line (1) implies that $b \leq 0$. \\
Line (2) implies that $w_2 + b > 0$. \\
Line (3) implies that $w_1 + b > 0$. \\
Line (4) implies that $w_1 + w_2 + b \leq 0$. \\

Lines (2) and (3) imply that $w_1 > -b$ and $w_2 > -b$. \\
Then $w_1 + w_2 + b > (-b) + (-b) + b = -b \geq 0$. \\
So $w_1 + w_2 + b > 0$, which contradicts line (4). \\
Therefore the assumption is false and no perceptron can compute XOR. \\

\end{proof}

However, a multilayer perceptron network can be designed to compute XOR.
One way to demonstrate this is by constructing a network of perceptrons weighted to compute NAND.
Then XOR can be computed because $\{\textrm{NAND}\}$ is functionally complete; that is, all boolean functions can be expressed as
a composition of NAND.
\begin{defn}
Let $S$ be a set of truth functions. Then S is functionally complete iff all possible truth functions are definable from $S$\cite{proofwiki_nand}.
\end{defn}

The following proof borrows heavily from ProofWiki\cite{proofwiki_four_functionally_complete}.

\begin{proof}
Let $\{0,1\}$ be the set of truth values, with 0 signifying a false value and 1 signifying a true value.
Consider the following truth table of binary boolean functions. On the left side are the two inputs $x_1$ and $x_2$.
Because there are two inputs, each of which can assume two values, there are four possible inputs, yielding $2^4 = 16$ possible outputs.
Thus the listing on the right side of the table of binary functions is exhaustive.

For purposes of readability the table has been broken horizontally into two halves.

\begin{center}
\begin{tabular}{rr|rrrrrrrrrrrrrrrr}
$x_1$ & $x_2$ & $f_F$ & AND & $(\lnot \Rightarrow)$ & $\textrm{pr}_1$ & $(\lnot \Leftarrow)$ & $\textrm{pr}_2$ & XOR & OR \\
\hline
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1\\
1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1\\
1 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1\\ \\
$x_1$ & $x_2$ & NOR & $\Leftrightarrow$ & $(\lnot \textrm{pr}_2)$ & $\Leftarrow$ & $(\lnot \textrm{pr}_1)$ & $\Rightarrow$ & NAND & $f_T$ \\
\hline
0 & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\\
0 & 1 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1\\
1 & 0 & 0 & 0 & 1 & 1 & 0 & 0 & 1 & 1\\
1 & 1 & 0 & 1 & 0 & 1 & 0 & 1 & 0 & 1\\
\end{tabular}
\end{center}

The following table will demonstrate that the set $S_1 = \{\lnot, \Rightarrow, \textrm{AND}, \textrm{OR}\}$ is functionally complete.
Each possible binary boolean function not in $S_1$ is listed down the first column.
An equivalent expression for each is function is written in the second column.
The third column contains the set of boolean functions that have been used so far in the chart without having an equivalent expression given for them.

\begin{center}
\begin{tabular}{r|l|l}
Function & Equivalent Expression & Functions Used So Far \\ \hline
$f_T$ & $x_1 \Leftrightarrow x_1$ & $\{\Leftrightarrow\}$ \\
$f_F$ & $x_1 \textrm{XOR} x_1$    & $\{\Leftrightarrow, \textrm{XOR}\}$ \\
XOR   & $\lnot( x_1 \Leftrightarrow x_2 )$ & $\{\Leftrightarrow, \lnot\}$ \\
$\Leftrightarrow$ & $(x_1 \Rightarrow x_2) \textrm{AND} (x_1 \Leftarrow x_2)$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow\}$ \\
$(\lnot \textrm{pr}_1)$ & $\lnot \textrm{pr}_1$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow, \textrm{pr}_1\}$ \\
$(\lnot \textrm{pr}_2)$ & $\lnot \textrm{pr}_2$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow, \textrm{pr}_1, \textrm{pr}_2\}$ \\
$\textrm{pr}_1$ & $x_1 \textrm{AND} x_1$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow, \textrm{pr}_2\}$ \\
$\textrm{pr}_2$ & $x_2 \textrm{AND} x_2$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow\}$ \\
NAND & $\lnot( x_1 \textrm{AND} x_2 )$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow\}$ \\
NOR  & $\lnot( x_1 \textrm{OR}  x_2 )$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow, \textrm{OR}\}$ \\
$(\lnot \Rightarrow)$ & $\lnot \Rightarrow$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow, \textrm{OR}\}$ \\
$(\lnot  \Leftarrow)$ & $\lnot  \Leftarrow$ & $\{\lnot, \textrm{AND}, \Rightarrow, \Leftarrow, \textrm{OR}\}$ \\
$\Leftarrow$ & $x_2 \Rightarrow x_1$ & $\{\lnot, \textrm{AND}, \Rightarrow, \textrm{OR}\}$ \\
\end{tabular}
\end{center}

Thus $S_1$ is functionally complete.

Now consider another table similar to the one above; however, in this table $S_1$ is shown to be definable from $S_2 = \{\textrm{NAND}\}$.
\begin{center}
\begin{tabular}{r|l|l}
Function & Equivalent Expression & Functions Used So Far \\ \hline
$\Rightarrow$ & $\lnot( x_1 \textrm{AND} \lnot x_2)$ & $\{ \lnot, \textrm{AND} \}$ \\
OR & $\lnot( \lnot x_1 \textrm{AND} \lnot x_2)$ & $\{ \lnot, \textrm{AND} \}$ \\
$\lnot$ & $x_1 \textrm{NAND} x_1$ & $\{ \textrm{AND}, \textrm{NAND} \}$ \\
AND & $(x_1 \textrm{NAND} x_2) \textrm{NAND} (x_1 \textrm{NAND} x_2)$ & $\{ \textrm{NAND} \}$ \\
\end{tabular}
\end{center}

Therefore $S_1$ can be expressed from $S_2$.
Since $S_1$ is functionally complete this implies that $S_2$ is functionally complete.

\end{proof}

# TODO show the design of a network that does XOR
\begin{figure}[h]
\begin{center}
\includegraphics{xor_network.png}
\caption{A neural network that computes XOR.}
\label{fig:xor_network}
\end{center}
\end{figure}
#+LATEX: See Figure~\ref{fig:xor_network} for the design of a neural network that computes XOR.
# Below is a truth table for that network.
# TODO: insert the truth table here.

** Statement and Proof of the Turing-completeness of Certain Recurrent Neural Networks
# TODO ensure that recurrent is defined in the introduction
As was alluded to before, recurrent neural networks are Turing-complete.

The Turing machine is a conceptual machine proposed by Alan Turing to provide a definition for the idea of computability.
The description of a Turing machince is based on Turing's 1936 paper\cite{Turing1936}.

The Turing machine has a finite number of conditions called m-configurations that it can be in.
It has a "tape" of infinite length which is divided into "squares" containing "symbols" which can be read one at a time by a "reader".
The machine can read and write symbols onto the square of the tape directly under the reader and can move the tape back and forth underneath the
reader. In this manner the Turing machine can perform any computation; for a more detailed description and discussion see Turing's paper\cite{Turing1936}.

In lieu of expressing m-configurations and such in terms of neural networks we shall utilize a common strategy
for proving Turing-completeness: implementing a language which has already been shown to be Turing-complete.
If a language is Turing-complete, then it can express any algorithm since the Turing machine is universal.
If we can implement the language using a recurrent neural network then it follows by transitivity that our network is also Turing-complete.

The following proof is largely based on a 1996 paper by Heikki Hyötyniemi\cite{turing_machines_are}.

Consider the following language $\mathbb{L}$, which consists of the following four instructions:
#+LATEX: \begin{tabular}{lll}
#+LATEX: name & operation                      & description        \\ \hline
#+LATEX: inc  & $V' \leftarrow V + 1$          & increment          \\
#+LATEX: dec  & $V' \leftarrow \textrm{max}(0, V - 1)$  & decrement          \\
#+LATEX: nop  & $V' \leftarrow V$              & no operation       \\
#+LATEX: goto & if $V \neq 0$ goto $j$         & conditional branch \\
#+LATEX:\end{tabular} \linebreak where $V, j \in \mathbb{Z}$ such that $V,j \geq 0$.

It is known that $\mathbb{L}$ is Turing-complete\cite{turing_machines_are}.
Also note that the decrement operator precludes the possibility of negative variable values.
This is due to the following activation function used for the purposes of this proof:
\begin{equation}
\label{eqn:proof_neuron}\phi(x) = \left\{ \begin{array}{lr} x & : x > 0 \\ 0 & : x \leq 0 \end{array} \right.
\end{equation}

To elucidate the proof an example will be interspersed throughout the proof.
The following program \texttt{example-prog} in $\mathbb{L}$ will be implemented using a recurrent neural network:
#+begin_src L
0: dec V0
1: inc V1
2: if V0 != 0 goto 0
3: nop
#+end_src
The program has two variables, \texttt{V0} and \texttt{V1}.
While $\texttt{V0} \neq 0$ the program loops.

*** Procedure for Creating Network
Given an input program $P$, create the following neurons: \\
# Create a neuron called $I$ which will be used to fire the first instruction neuron when computation starts. \\
    - For each variable $i$ in $P$, create a variable neuron $V_i$. \\
    - For each line $j$ in $P$, create a instruction neuron $N_j$. \\
    - Replace any \texttt{goto} instruction neuron $N_j$ that references line $j+1$ with a \texttt{nop} instruction neuron.\footnote{This is valid because the execution will branch to the next instruction in both cases of the referenced variable $V > 0$ and $V=0$.}
    - For each \texttt{goto} in $P$, create two transition neurons $N'_j$ and $N''_j$, given that $j$ is the line number of the \texttt{goto}. \\
# \\ \texttt{ 0: if V0 != 0 goto 1 \\ 1: nop} and \\ \texttt{0: nop \\ 1: nop} \\ are equivalent. Such a \texttt{goto} will always branch to the next line.}

Then connect the neurons as follows:
#    - Create a connection with a weight of  1 between $I$ and $N_0$.
#    - Create a connection with a weight of -1 between $I$ and itself.
   - Create a connection with a weight of 1 between each variable neuron $V_i$ and itself.
     This feedback loop keeps the value of $V_i$ consistent between iterations unless otherwise modified.
   - Create a connection with a weight of  1 between each \texttt{inc} instruction neuron $N_j$ and the variable $V_i$ that is being incremented.
   - Create a connection with a weight of -1 between each \texttt{dec} instruction neuron $N_j$ and the variable $V_i$ that is being decremented.
   - Create a connection with a weight of  1 between each \texttt{inc}, \texttt{dec}, or \texttt{nop} instruction neuron $N_j$ and $N_{j+1}$.
   - Create a connection with a weight of  1 between each \texttt{goto} instruction neuron $N_j$ and the transition neurons $N'_j$ and $N''_j$.
   - Create a connection with a weight of  1 between each $N'_j$  transition neuron and the instruction neuron referenced by the $N_j$ \texttt{goto}.
   - Create a connection with a weight of -1 between each $N''_j$ transition neuron and the instruction neuron referenced by the $N_j$ \texttt{goto}.
   - Create a connection with a weight of  1 between each $N''_j$ transition neuron and the instruction neuron $N_{j+1}$.
# TODO Create a connection with a weight of -1 between each $V_i$ variable neuron and the $N''_j$ transition neuron$.
# TODO handle the j+1 is off of the program (sometimes it doesn't exist).

#+LATEX: A realization of \texttt{example-prog} is given in Figure~\ref{fig:turing-example}.
# The output of the network is run to the bus on the right side of the diagram, through the unit delay, and fed back into
# the network on the left side.
To ease readability of the diagram, the outputs have been drawn as a bus.
The outputs are run into the bus on the right side of the diagram, go through the unit delay (to distinguish between iterations), 
and come back out on the left side as inputs.
For example, the output of $N_0$ runs to position $1$ on the bus, which is then connected to $N_1$.
The network is said to /iterate/ each time the network output is run through the unit delay.
It is important to note that \texttt{nop}, \texttt{inc}, and \texttt{dec} each take one iteration to execute,
a \texttt{goto} takes two iterations to execute.
#+LATEX: Table~\ref{table:example-prog-iteration-table} below gives the value of each position at each iteration.
Note that the $0^{th}$ iteration contains the initial values on the bus.
These will be set according to the rules for creating an /initial state/, detailed below.

The inputs to a neuron at iteration $k, k \geq 1$ can be written as equations, which are given below.
These equations reflect the nature of a network constructed according to the above procedure.
Let $N(k)$ be the input of the neuron $N$ at iteration $k$.
# TODO the seperators in the second nested spot look like minus signs
     - 1) $V_i$ has an input of
       V_i(k-1) + \Sigma_{a \in \textrm{inc}} N_a(k) - \Sigma_{b \in \textrm{dec}} N_b(k)
       at iteration $k$ where \textrm{inc} is the set of \texttt{inc} instructions referencing $V_i$ and \textrm{dec} is the set of \texttt{dec} instructions referencing $V_i$.
     - 2) $N_j$ has an input at iteration $k$ of 
       - a) $N_{j-1}(k-1) + \Sigma_{g \in goto}(N'_g(k-1) - N''_g(k-1))$ if line $j-1$ is an \texttt{inc}, \texttt{dec}, or \texttt{nop}
       - b) $N''_{j-1}(k-1)+ \Sigma_{g \in goto}(N'_g(k-1) - N''_g(k-1))$ if line $j-1$ is a \texttt{goto}, where \textrm{goto} is the set of lines that are \texttt{goto}s referencing $N_j$.
     - 3) $N'_j$ has an input of $N_j(k-1)$ at iteration $k$.
     - 4) $N''_j$ has an input of $N_j(k-1) - V(k-1)$ at iteration $k$ where $V$ is the variable referenced in the \texttt{goto} statement.
#     - 5) $I$ has an input of $-I(k-1)$ at iteration $k$.
# Also note that the box labeled "Initial State" outputs 1 during the calculation of the first iteration and outputs 0 afterward.

# Thus the aggregate input to each neuron is as follows:
#    - $V_i$ has an aggregate input of
#      \begin{equation}
#      \label{eqn:variable} V_i + \Sigma_{j \in x} N_j - \Sigma_{j \in y} N_j + \Sigma_{j \in z} N'_j - \Sigma_{j \in z} N''_j
#      \end{equation}
#      where $x$ is the set of \texttt{inc} neurons referencing that variable, $y$ is the set of \texttt{dec} neurons referencing that variable, and $z$ is the set of \texttt{goto} neurons refrencing that variable.
#    - $N_j$ has an aggregate input of
#      \begin{equation}
#      \label{eqn:instruction} \Sigma_{r \in w} N_r + \Sigma_{s \in z} (N'_s - N''_s)
#      \end{equation}
#      where $w$ is $\{ N_{j-1} \}$ if both $j-1 \geq 0$ and $N_{j-1}$ corresponds to a \texttt{inc}, \texttt{dec}, or \texttt{nop} instruction. \\
#      $w$ is $\{\}$ otherwise. \\
#      $z$ is the set of \texttt{goto} neurons referencing that instruction neuron. \\
# #     If $N_{j-1}$ does not exist then that term is zero.
#    - $N'_j$ has an aggregate input of
#      \begin{equation}
#      \label{eqn:transition-one} N_j
#      \end{equation}
#    - $N''_j$ has an aggregate input of
#      \begin{equation}
#      \label{eqn:transition-two} N_j - V
#      \end{equation}
#      where $V$ is the variable referenced by the \texttt{goto}.


# TODO I plan to extend Hyötyniemi's proof by demonstrating how to achieve similar results with a more traditional perceptron definition.

\begin{figure}
\begin{center}
\includegraphics[width=3.5in]{turing_example.png}
\caption{The neural network for \texttt{example-prog}.}
\label{fig:turing-example}
\end{center}
\end{figure}



\begin{figure}
\begin{center}
\begin{tabular}{r|rrrrrrrrrrr}
 & Iteration &  &  &  &  &  &  &  &  & \\
Position on bus & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10\\
\hline
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\
1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 & 0\\
2 & 2 & 1 & 1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0\\
3 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\
4 & 0 & 0 & 1 & 1 & 1 & 1 & 2 & 2 & 2 & 2 & 2\\
5 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0\\
6 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 0\\
7 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 0\\
8 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0\\
\end{tabular}
\end{center}
\caption{Inputs of each position on bus at each iteration.}
\label{table:example-prog-iteration-table}
\end{figure}
# |                 | Iteration |   |   |   |   |   |   |   |   |   |
# |               / |         < |   |   |   |   |   |   |   |   |   |
# | Position on bus |         0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
# |-----------------+-----------+---+---+---+---+---+---+---+---+---|
# |               0 |         0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 |
# |               1 |         2 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 |
# |               2 |         0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 |
# |               3 |         0 | 0 | 1 | 1 | 1 | 1 | 2 | 2 | 2 | 2 |
# |               4 |         0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 |
# |               5 |         0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 1 | 0 |
# |               6 |         0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 |


# TODO fix section about states.
*** States of the Network
\begin{defn}
A neural network's state is \textit{initial} provided that: \\
   - The input of $N_0$ is 1. \\
   - The input of all variable neurons is their initial value as given in the program in $\mathbb{L}$. \\
   - All other neurons have an input of 0.
\end{defn}
The inputs at the $0^{\textrm{th}}$ iteration must be set so that the network is in the /initial/ state.

\begin{defn}
A neural network's state is \textit{legal} provided that: \\
- At most one instruction neuron $N_j$ has an input of 1, the others have an input of 0. \\
- All transition neuron $N'_j$ and $N''_j$ have an input of 0.
\end{defn}

\begin{defn}
A neural network's state is \textit{transitory} provided that: \\
- All instruction neurons $N_j$ input 0. \\
- There exists a unique $j$ such that at least one of the transition neurons $N'_j$ and $N''_j$ input 1. \\
- All other transition neurons have an input of 0.
\end{defn}

\begin{defn}
A neural network's state is \textit{final} provided that: \\
- All transition and instruction nodes have an input of 0.
\end{defn}

If the network is in the final state then execution halts.
# The network is in the \textit{final} state provided that all transition and instruction nodes have an output of 0.

# To initialize the network, all instruction and transition neurons must have an output of 0.
# The first instruction is then given an input of $1$ on the $0^{th}$ iteration.
# #+ALTEX: This is pictured by the "Initial State" box on Figure~\ref{fig:turing-example}.
# The "Initial State" box outputs 1 on the $0^{th}$ iteration and outputs 0 afterward.

We will show that the network is initialized so that the first iteration is a legal state, after which we will induct on the current instruction
to show the instructions in the program are executed correctly and in order.

# is either in a legal or final state and that the instruction was carried out and that
# therefore the network properly implements the program.

\begin{theorem}
Using the procedure above a neural network can be constructed to implement any program in $\mathbb{L}$.
Consequently recurrent neural networks are Turing-complete.
\end{theorem}

\begin{proof}
Let $P$ be a program in $\mathbb{L}$. Let the network be constructed to implement $P$ according to the above procedure.

Induction Hypothesis:
Let the network be in a legal state at the $k^{th}$ iteration,
with the activated instruction neuron $N_j$ having an input of 1, with all instructions antecedent to instruction $j$ in the execution of the program having been correctly executed.
Then the following will be shown: \\
- 1) The instruction at line $j$ in the program will be executed. \\
- 2) The network will be in a legal state after execution of the instruction at line $j$. \\
- 3) The instruction neuron corresponding to the next instruction in the execution of the program will have an input of 1, or the network will be in the final state in which case execution halts. \\

~\\\textit{Base Case:}\\
By the definition of the initial state, the following are true: \\
- 1) The network is in a legal state. \\
- 2) The instruction neuron corresponding to the first instruction in the program, $N_0$, has an input of 1. \\
- 3) All instructions previous to $j=0$ have necessarily been executed correctly because there are no instructions previous to instruction 0 in the program. \\
Thus the initialized network meets the requirements for the induction step. \\

~\\\textit{Induction Step:}\\
Let the network be in a legal state at the $k^{th}$ iteration,
with the activated instruction neuron $N_j$ having an input of 1, with all instructions antecedent to instruction $j$ having been correctly executed.

The input of a neuron $N$ at iteration $k$ will be denoted as $N(k)$.

Note that the outputs of iteration $k$ are the inputs for iteration $k+1$.

Consider the following exhaustive list of cases for the instruction associated with $N_j$:

\texttt{nop}: \\
$\left\{ \begin{array}{l} N_j(k) = 1 \\ N_{j+1}(k) = 0 \end{array} \right.$ by the definition of a legal state. \\
Therefore: \\
$\left\{ \begin{array}{l} N_j(k+1) = 0 \textrm{ by equation (2a)} \\ N_{j+1}(k+1) = 1 \textrm{ by equation (2a)} \end{array} \right.$ \\
All other instruction neurons will have an input of 0 at iteration $k+1$ \\
All variable neurons will retain their respective values at iteration $k+1$. \\
All transition neurons will have an input of 0 at iteration $k+1$. \\
Thus the network is in a legal state. \\
The values of all variables have stayed the same, and the current instruction number was incremented; therefore \texttt{nop} executed correctly.

\texttt{dec}: \\
Let $V$ be the variable neuron referenced by the \texttt{dec} instruction. \\
$\left\{ \begin{array}{l} V(k) = v \\ N_j(k) = 1 \\ N_{j+1}(k) = 0 \end{array} \right.$ for $v \geq 0$ by the definition of a legal state. \\
Therefore: \\
$\left\{ \begin{array}{l} V(k+1) = \textrm{max}(0, v - 1) \textrm{ by equation (1)} \\ N_j(k+1) = 0 \textrm{ by equation (2a)} \\ N_{j+1}(k+1) = 1 \textrm{ by equation (2a)} \end{array} \right.$ \\
$V(k+1) = \textrm{max}(0, v - 1)$ because the input to $V$ at iteration $k+1$ is $v - 1$ and the neurons as we have defined them cannot output negative values. \\
All other instruction neurons will have an input of 0 at iteration $k+1$ \\
All other variable neurons will retain their respective inputs at iteration $k+1$. \\
All transition neurons will have an input of 0 at iteration $k+1$. \\
Thus the network is in a legal state. \\
The values of all variables have stayed the same except for the variable referenced, which has decreased by one (or remained at zero), and the current instruction number was incremented; therefore \texttt{dec} executed correctly.

\texttt{inc}: This is similar to \texttt{dec} except $V(k+1) = v + 1$ instead of $\textrm{max}(0, v - 1)$.

\texttt{goto}: \\
Let $m$ be the line referenced by the \texttt{goto} (i.e. \texttt{if V0 != 0 goto m}). \\
Note that $m \neq j+1$ because such an instruction was replaced with a \texttt{nop} in the network creation procedure. \\

Let $V$ be the variable neuron referenced by the \texttt{goto} instruction. \\

First consider the case where $V(k) = 0$ \\
$\left\{ \begin{array}{l} V(k) = 0 \\ N_j(k) = 1 \\  N'_j(k) = 0 \\ N''_j(k) = 0 \\ N_m(k) = 0 \\ N_{j+1}(k) = 0 \end{array} \right.$ by the definition of a legal state. \\
Therefore: \\ 
$\left\{ \begin{array}{l} V(k+1) = 0 \textrm{ by equation (1)} \\ N_j(k+1) = 0 \textrm{ by equation (2a)} \\  N'_j(k+1) = 1 \textrm{ by equation (3)} \\ N''_j(k+1) = 1 \textrm{ by equation (4)} \\ N_m(k+1) = 0 \textrm{ by equations (2a) and (2b)} \\ N_{j+1}(k+1) = 0 \textrm{ by equation (2b)}\end{array} \right.$ \\
Note that the network is now in a transition state.
Then: \\
$\left\{ \begin{array}{l} V(k+2) = 0 \textrm{ by equation (1)} \\ N_j(k+2) = 0 \textrm{ by equation (2a)} \\  N'_j(k+2) = 0 \textrm{ by equation (3)} \\ N''_j(k+2) = 0 \textrm{ by equation (4)} \\ N_m(k+2) = 0 \textrm{ by equations (2a) and (2b)} \\ N_{j+1}(k+2) = 1 \textrm{ by equation (2b)}\end{array} \right.$ \\
All other instruction neurons will have inputs of 0 at iterations $k+1$ and $k+2$. \\
All other variable neurons will retain their respective inputs at iterations $k+1$ and $k+2$. \\
The network is back in a legal state (or final state, if $N_{j+1}$ does not exist) at iteration $k+2$.\\
Since the instruction neuron that now has an input of 1 is $N_{j+1}$ the \texttt{goto} was correctly executed. \\ 

Next consider the case where $V(k) = v > 0$ (which implies that $v \geq 1$ because $V \in \mathbb{Z}$): \\
$\left\{ \begin{array}{l} V(k) = v \\ N_j(k) = 1 \\  N'_j(k) = 0 \\ N''_j(k) = 0 \\ N_m(k) = 0 \\ N_{j+1}(k) = 0 \end{array} \right.$ by the definition of a legal state. \\
Therefore: \\ 
$\left\{ \begin{array}{l} V(k+1) = v \textrm{ by equation (1)} \\ N_j(k+1) = 0 \textrm{ by equation (2a)} \\  N'_j(k+1) = 1 \textrm{ by equation (3)} \\ N''_j(k+1) = 0 \textrm{ by equation (4)} \\ N_m(k+1) = 0 \textrm{ by equations (2a) and (2b)} \\ N_{j+1}(k+1) = 0 \textrm{ by equation (2b)} \end{array} \right.$ \\
Note that the network is now in a transition state.
Then: \\
$\left\{ \begin{array}{l} V(k+2) = v \textrm{ by equation (1)} \\ N_j(k+2) = 0 \textrm{ by equation (2a)} \\  N'_j(k+2) = 0 \textrm{ by equation (3)} \\ N''_j(k+2) = 0 \textrm{ by equation (4)} \\ N_m(k+2) = 1 \textrm{ by equations (2a) and (2b)} \\ N_{j+1}(k+2) = 0 \textrm{ by equation (2b)} \end{array} \right.$ \\
All other instruction neurons will have inputs of 0 at iterations $k+1$ and $k+2$. \\
All other variable neurons will retain their respective inputs at iterations $k+1$ and $k+2$. \\
The network is back in a legal state (or final state, if $N_{j+1}$ does not exist) at iteration $k+2$.\\
Since the instruction neuron that has an input of 1 is $N_{m}$ the \texttt{goto} was correctly executed. \\ 

Thus all instructions are carried out.
Since the network can implement any program in $\mathbb{L}$, it follows that recurrent neural networks are Turing-complete.
\end{proof}

** Conclusion

In this paper the theoretical capabilities of neural networks were explored.
Not only can a neural network compute the boolean functions, but recurrent neural networks are Turing-complete.
The Turing-completeness is promising for the future of neural networks;
however, to utilize this potential new learning algorithms and network designs will need to be developed in order to train
recurrent networks as efficiently as the algorithm currently used to train feed-forward networks.

# that can be programmed to compute any possible computer algorithm.
# Let $C$ be a system of computing.
# $C$ is said to be Turing-complete if computers of type $C$ are capable of simulating any single-taped Turing machine.
# Closely related is the idea of Turing equivalence, that a Turing machine can simulate any computer of type $C$.
# Then, by the transitive property, it follows that all Turing-equivalent computers can simulate each other.

# TODO prove Turing-completeness

# ** Statement and Proof of the Universality Theorem
# In the previous section it was shown that recurrent neural networks can compute any function that can be computed by an algorithm.
# More impressively, it is also true that a neural network with only a single hidden layer can compute any continuous function to an arbitrary degree
# of precision. This is known as the Universality Theorem.

# ** Statement and Proof of Correctness for a Training Algorithm for a Perceptron
# The power and versatility of neural networks in general was shown in the previous sections;
# however, what are the capabilities of a single neuron?
# A perceptron neuron can be used to classify linearly separable data.
# In this section a network design and a training algorithm will be stated,
# and the ability of the network to correctly classify all data in the training set, provided the training set is linearly separable, will be proven.

\begin{thebibliography}{9}
\bibitem{Turing1936}
Alan M. Turing, "On Computable Numbers, With An Application To The Entscheidungsproblem", Princeton University, 1936

\bibitem{DeepLearning}
Michael A. Nielsen, "Neural Networks and
Deep Learning", Determination Press, 2014

\bibitem{proofwiki_nand}
\url{https://proofwiki.org/wiki/Definition:Logical_NAND}

\bibitem{proofwiki_four_functionally_complete}
\url{https://proofwiki.org/wiki/Functionally_Complete_Logical_Connectives/Negation,_Conjunction,_Disjunction_and_Implication}

\bibitem{comp_foundation}
Simon Haykin, "Neural Networks: A Comprehensive Foundation", Maxwell Macmillan International, 1994

\bibitem{turing_machines_are}
Heikki Hyötyniemi, "Turing Machines are Recurrent Neural Networks", Publications of the Finnish Artificial Intelligence Society, pp. 13-24,
\url{http://lipas.uwasa.fi/stes/step96/step96/hyotyniemi1/}

\end{thebibliography}
