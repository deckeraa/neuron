<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title></title>
<!-- 2014-09-18 Thu 01:18 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title"></h1>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1"><span class="section-number-2">1</span> Neural Networks</h2>
<div class="outline-text-2" id="text-1">
</div>

<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1"><span class="section-number-3">1.1</span> Project Schedule</h3>
<div class="outline-text-3" id="text-1-1">
</div><div id="outline-container-sec-1-1-1" class="outline-4">
<h4 id="sec-1-1-1"><span class="section-number-4">1.1.1</span> Introduction Paper due 9/25/2014</h4>
</div>
<div id="outline-container-sec-1-1-2" class="outline-4">
<h4 id="sec-1-1-2"><span class="section-number-4">1.1.2</span> Demonstration of the Equivalence of Various Perceptrons Networks due 2014-09-23</h4>
</div>
<div id="outline-container-sec-1-1-3" class="outline-4">
<h4 id="sec-1-1-3"><span class="section-number-4">1.1.3</span> Statement and Proof of Perceptron Training algorithm due 2014-09-30</h4>
</div>
<div id="outline-container-sec-1-1-4" class="outline-4">
<h4 id="sec-1-1-4"><span class="section-number-4">1.1.4</span> Turing Equivalence 2014-09-30</h4>
</div>
<div id="outline-container-sec-1-1-5" class="outline-4">
<h4 id="sec-1-1-5"><span class="section-number-4">1.1.5</span> Universality Theorem 2014-10-07</h4>
</div>
<div id="outline-container-sec-1-1-6" class="outline-4">
<h4 id="sec-1-1-6"><span class="section-number-4">1.1.6</span> Statement and Proof of Backpropogation algo? 2014-10-14</h4>
</div>
</div>
<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2"><span class="section-number-3">1.2</span> Overview of Neural Networks</h3>
<div class="outline-text-3" id="text-1-2">
<p>
A neural network is a system in which many similar functions, called <i>neurons</i>, are composed together in order to classify inputs, perform some computation,
or approximate some function.
Neural networks are used today in various machine-learning applications such as handwriting- or speech-recognition, and have several interesting mathematical properties.
</p>
</div>

<div id="outline-container-sec-1-2-1" class="outline-4">
<h4 id="sec-1-2-1"><span class="section-number-4">1.2.1</span> Definition of a Neuron</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
A neuron is a function \(f(x_1, x_2, \ldots, x_n) = \phi( \Sigma_{i=1}^n w_ix_i )\), where \(\{w_1, w_2, \ldots\, w_n\}\) is a set of weights,
with each weight \(w_i\) corresponding to an input \(x_i\), and where \(\phi\) is the activation function that determines the output of the neuron based
on the sum of the products of the weights and inputs. For the sake of brevity we will also notate the weight and input vectors as \(\vec{w}\) and \(\vec{x}\), respectively.
</p>

<p>
A neuron could be also thought of as a partial application of \(\phi\) and \(\vec{w}\) over the factory function \(F( \phi, \vec{w}, \vec{x} )\).
</p>

<p>
There are two popular activation functions, the perceptron and the sigmoid function.
The perceptron can be defined as the function
\[\phi_P(x) = \left\{ \begin{array}{lr} 0 & : x + b \leq 0 \\ 1 & : x + b > 0 \end{array} \right.\]
where \(b\) is a bias that is specific to the neuron.
</p>

<p>
The sigmoid function can be defined as \(\sigma(x) = \frac{1}{1 + e^{-x}}\).
Though bearing some resemblance to the perceptron, the sigmoid function has the advantage of being both smooth and differentiable.
These properties make training a neural network much easier.
</p>
</div>
</div>
</div>
<div id="outline-container-sec-1-3" class="outline-3">
<h3 id="sec-1-3"><span class="section-number-3">1.3</span> Demonstration of the Equivalence of Various Perceptron Networks to Certain Boolean Logic Functions</h3>
<div class="outline-text-3" id="text-1-3">
<p>
Consider the following network consisting of one perceptron-type neuron, with inputs \(\ncol{x_1 \\ x_2}\). <br  />
Let \(\vec{w} = \ncol{1 \\ 1}\) and \(b=-1\).
Compare the behavior of the network to that of the AND function: <br  />
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="right" />

<col  class="right" />
</colgroup>

<colgroup>
<col  class="right" />

<col  class="right" />

<col  class="right" />
</colgroup>

<colgroup>
<col  class="right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="right">\(x_1\)</th>
<th scope="col" class="right">\(x_2\)</th>
<th scope="col" class="right">\(\vec{x}\odot\vec{w}\)</th>
<th scope="col" class="right">\(\vec{x}\odot\vec{w} + b\)</th>
<th scope="col" class="right">Output</th>
<th scope="col" class="right">\(x_1\) AND \(x_2\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">-1</td>
<td class="right">0</td>
<td class="right">0</td>
</tr>

<tr>
<td class="right">0</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
</tr>

<tr>
<td class="right">1</td>
<td class="right">0</td>
<td class="right">1</td>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
</tr>

<tr>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">2</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
Note how the network is equivalent to the AND function over the inputs for which AND is defined.
</p>

<p>
Now let \(\vec{w} = \ncol{1 \\ 1}\) and \(b=0\).
Compare the behavior of the network to that of the AND function: <br  />
</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="right" />

<col  class="right" />
</colgroup>

<colgroup>
<col  class="right" />

<col  class="right" />

<col  class="right" />
</colgroup>

<colgroup>
<col  class="right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="right">\(x_1\)</th>
<th scope="col" class="right">\(x_2\)</th>
<th scope="col" class="right">\(\vec{x}\odot\vec{w}\)</th>
<th scope="col" class="right">\(\vec{x}\odot\vec{w} + b\)</th>
<th scope="col" class="right">Output</th>
<th scope="col" class="right">\(x_1\) OR  \(x_2\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
<td class="right">0</td>
</tr>

<tr>
<td class="right">0</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">1</td>
</tr>

<tr>
<td class="right">1</td>
<td class="right">0</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">1</td>
</tr>

<tr>
<td class="right">1</td>
<td class="right">1</td>
<td class="right">2</td>
<td class="right">2</td>
<td class="right">1</td>
<td class="right">1</td>
</tr>
</tbody>
</table>
<p>
Now, simply by changing the weights, the network output becomes equivalent to the OR function over the domain of OR.
</p>

<p>
TODO: expand this section to include NAND (since all logic functions can be expressed with NAND?) and XOR (I read that there were difficulties
in creating this network back in the 70's before backpropogation).
</p>
</div>
</div>
<div id="outline-container-sec-1-4" class="outline-3">
<h3 id="sec-1-4"><span class="section-number-3">1.4</span> Statement and Proof of Correctness for a Training Algorithm for a Perceptron</h3>
</div>

<div id="outline-container-sec-1-5" class="outline-3">
<h3 id="sec-1-5"><span class="section-number-3">1.5</span> Statement and Proof of the Turing-completeness of Neural Networks</h3>
</div>

<div id="outline-container-sec-1-6" class="outline-3">
<h3 id="sec-1-6"><span class="section-number-3">1.6</span> Statement and Proof of the Universality Theorem</h3>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2014-09-18 Thu 01:18</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 24.3.1 (<a href="http://orgmode.org">Org</a> mode 8.0)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
